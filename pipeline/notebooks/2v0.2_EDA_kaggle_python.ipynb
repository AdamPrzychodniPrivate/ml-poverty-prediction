{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3783d70",
   "metadata": {
    "papermill": {
     "duration": 0.011988,
     "end_time": "2024-01-03T14:51:18.081057",
     "exception": false,
     "start_time": "2024-01-03T14:51:18.069069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 align=\"center\">\n",
    "    Run this notebook in Kaggle notebooks<br />\n",
    "    (Language - Python)\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e37f1b",
   "metadata": {
    "papermill": {
     "duration": 0.011374,
     "end_time": "2024-01-03T14:51:18.104570",
     "exception": false,
     "start_time": "2024-01-03T14:51:18.093196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [Link to Kaggle Notebook](https://www.kaggle.com/code/adamprzychodni/2v0-2-eda-kaggle-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3711c5b",
   "metadata": {
    "papermill": {
     "duration": 0.011936,
     "end_time": "2024-01-03T14:51:18.128187",
     "exception": false,
     "start_time": "2024-01-03T14:51:18.116251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95018885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T14:51:18.154023Z",
     "iopub.status.busy": "2024-01-03T14:51:18.153554Z",
     "iopub.status.idle": "2024-01-03T14:51:18.169940Z",
     "shell.execute_reply": "2024-01-03T14:51:18.167495Z"
    },
    "papermill": {
     "duration": 0.032535,
     "end_time": "2024-01-03T14:51:18.172636",
     "exception": true,
     "start_time": "2024-01-03T14:51:18.140101",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# ydata-profiling installation for valuable automatic statistics on data distribution, central tendencies, and categorical variable frequencies\n",
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U ydata-profiling[notebook]\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b726b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62b8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T14:22:18.853605Z",
     "iopub.status.busy": "2024-01-03T14:22:18.853211Z",
     "iopub.status.idle": "2024-01-03T14:22:19.246310Z",
     "shell.execute_reply": "2024-01-03T14:22:19.244663Z",
     "shell.execute_reply.started": "2024-01-03T14:22:18.853574Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from typing import Union, List\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc544b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec8724",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Expand sidebar and Add Data - dataset \"ML Prediction of Poverty and Malnutrition Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703139ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:32:45.487278Z",
     "iopub.status.busy": "2024-01-03T13:32:45.486879Z",
     "iopub.status.idle": "2024-01-03T13:32:45.632776Z",
     "shell.execute_reply": "2024-01-03T13:32:45.630830Z",
     "shell.execute_reply.started": "2024-01-03T13:32:45.487251Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/ml-prediction-of-poverty-and-malnutrition-dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbaa07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:32:45.695791Z",
     "iopub.status.busy": "2024-01-03T13:32:45.695432Z",
     "iopub.status.idle": "2024-01-03T13:32:45.726980Z",
     "shell.execute_reply": "2024-01-03T13:32:45.726059Z",
     "shell.execute_reply.started": "2024-01-03T13:32:45.695766Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c36c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h2 align=\"center\">\n",
    "    &#x1F4A1; <strong>Conclusion_1</strong> - The Unnamed: 0 column is just an index and we don't need that, will be deleted in EDA - excluded in pipeline parameters_data_processing.yml - <span style=\"color:green;\">Done &#x2705;</span>\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde0a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:32:49.696465Z",
     "iopub.status.busy": "2024-01-03T13:32:49.695512Z",
     "iopub.status.idle": "2024-01-03T13:32:49.703750Z",
     "shell.execute_reply": "2024-01-03T13:32:49.702661Z",
     "shell.execute_reply.started": "2024-01-03T13:32:49.696439Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conclusion-1 \n",
    "# delete 'Unnamed: 0' column\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8f774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:32:51.878520Z",
     "iopub.status.busy": "2024-01-03T13:32:51.877876Z",
     "iopub.status.idle": "2024-01-03T13:32:51.910282Z",
     "shell.execute_reply": "2024-01-03T13:32:51.908652Z",
     "shell.execute_reply.started": "2024-01-03T13:32:51.878487Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c307e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307491c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404781bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Target Variables\n",
    "\n",
    "- **Stunted (Child Stunting):** Measures children under five years of age whose height-for-age z-score is less than -2.0 standard deviations below the median, according to the WHO Child Growth Standards. Stunting is a critical indicator of chronic malnutrition and reflects long-term nutritional status.\n",
    "\n",
    "- **Wasted (Child Wasting):** Refers to children under five whose weight-for-height is less than -2.0 standard deviations below the median, following WHO Child Growth Standards. This measure is essential for identifying acute malnutrition, reflecting recent and severe nutritional deficits.\n",
    "\n",
    "- **Healthy (Healthy Weight):** Identifies children under five whose weight-for-height falls within the normal range, typically between [-2.0, 2.0] standard deviations from the median, as per WHO Child Growth Standards. This category aims to pinpoint children who maintain an adequate nutritional status, free from stunting or wasting.\n",
    "\n",
    "- **Poorest (Asset Poverty):** Indicates households in the poorest quintile based on an asset-based comparative wealth index. This socioeconomic marker is crucial in understanding how material deprivation correlates with other forms of poverty.\n",
    "\n",
    "- **Underweight_bmi (Underweight Women):** Represents women aged 15 to 49 with a body mass index (BMI) below 18.5. This health indicator is vital for assessing maternal and child health, as undernutrition in women can have significant health impacts on both mothers and their children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560476c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.404403Z",
     "iopub.status.busy": "2024-01-03T13:00:45.404013Z",
     "iopub.status.idle": "2024-01-03T13:00:45.411713Z",
     "shell.execute_reply": "2024-01-03T13:00:45.409818Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.404371Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's see them :)\n",
    "df_with_target_variables = df[['stunted', 'wasted', 'healthy', 'poorest', 'underweight_bmi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486aecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.413741Z",
     "iopub.status.busy": "2024-01-03T13:00:45.413415Z",
     "iopub.status.idle": "2024-01-03T13:00:45.433345Z",
     "shell.execute_reply": "2024-01-03T13:00:45.432445Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.413698Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_with_target_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c1bd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Features\n",
    "\n",
    "- **URBAN_RURAL:** Denotes whether a location is urban or rural, a key factor in understanding geographical and socioeconomic disparities.\n",
    "\n",
    "- **alt (Altitude):** Represents the altitude of a location, influencing climate and environmental conditions.\n",
    "\n",
    "- **chrps (Climate Hazards Group InfraRed Precipitation with Station data):** Provides rainfall estimates vital for agricultural and climate studies.\n",
    "\n",
    "- **country:** Specifies the country of the data point, important for regional analysis.\n",
    "\n",
    "- **deathcount:** Counts the number of deaths in an area or period, significant for public health and safety studies.\n",
    "\n",
    "- **latnum (Latitude) and longnum (Longitude):** Geographic coordinates, essential for location-specific analysis.\n",
    "\n",
    "- **lst (Land Surface Temperature):** Key environmental and climate variable.\n",
    "\n",
    "- **markets0 to markets47:** Series of variables related to market food prices, critical for understanding economic conditions and food security. (Note: Clarify these variables with examples or a more detailed explanation.)\n",
    "\n",
    "- **numevents (Number of Significant Events):** Reflects the frequency of violent or significant events, indicating conflict and political instability's impact on food security and poverty.\n",
    "\n",
    "- **pasture:** Indicates pasture coverage, relevant in agricultural land use and environmental studies.\n",
    "\n",
    "- **sif (Solar-Induced Chlorophyll Fluorescence):** A measure of plant photosynthetic activity, crucial in agricultural and ecological research.\n",
    "\n",
    "- **slope:** Measures land steepness or gradient, relevant in geographical and environmental studies.\n",
    "\n",
    "- **tree:** Indicates tree coverage or density, significant in environmental, ecological, and climate studies.\n",
    "\n",
    "- **tt00_500k (Travel Time to Urban Centers):** Represents accessibility to urban centers, vital for understanding remoteness and socio-economic impacts.\n",
    "\n",
    "- **year:** Year of data collection, crucial for temporal analysis and trend identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af969140",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e9bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.435881Z",
     "iopub.status.busy": "2024-01-03T13:00:45.435232Z",
     "iopub.status.idle": "2024-01-03T13:00:45.449583Z",
     "shell.execute_reply": "2024-01-03T13:00:45.448080Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.435829Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_profiling(df: pd.DataFrame, name: str = \"data_profiling_report\",\n",
    "                   interface: str = \"html\", num_columns: int = None, chunk_size: int = 30) -> None:\n",
    "    \"\"\"\n",
    "    This function generates a data profiling report using the pandas_profiling package.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to profile.\n",
    "        name (str, optional): The title of the profile report. Defaults to \"data_profiling_report\".\n",
    "        interface (str, optional): The format of the report. Defaults to \"html\".\n",
    "                                    Choose between 'html' or 'widget'.\n",
    "        num_columns (int, optional): Number of columns to include in the report. If None, profiles in chunks of 30 columns.\n",
    "        chunk_size (int, optional): Size of each chunk for profiling when num_columns is None. Defaults to 30.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If df is not a pandas DataFrame or name is not a string or\n",
    "                    if interface is not 'html' or 'widget'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if df is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"df should be a pandas DataFrame\")\n",
    "\n",
    "    # Check if name is a string\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError(\"name should be a string\")\n",
    "\n",
    "    # Check if interface is a string and a valid option\n",
    "    if not isinstance(interface, str) or interface not in ['html', 'widget']:\n",
    "        raise ValueError(\"interface should be a string, either 'html' or 'widget'\")\n",
    "\n",
    "    # If num_columns is specified, profile only that many columns\n",
    "    if num_columns is not None:\n",
    "        if not isinstance(num_columns, int) or num_columns <= 0:\n",
    "            raise ValueError(\"num_columns should be a positive integer\")\n",
    "        columns_to_profile = df.columns[:num_columns]\n",
    "        df = df[columns_to_profile]\n",
    "        create_profile(df, name, interface)\n",
    "    else:\n",
    "        # If num_columns is not specified, profile in chunks\n",
    "        for start_col in range(0, len(df.columns), chunk_size):\n",
    "            end_col = min(start_col + chunk_size, len(df.columns))\n",
    "            chunk_columns = df.columns[start_col:end_col]\n",
    "            chunk_df = df[chunk_columns]\n",
    "            chunk_name = f\"{name}_{start_col + 1}-{end_col}\"\n",
    "            create_profile(chunk_df, chunk_name, interface)\n",
    "\n",
    "def create_profile(df, report_name, interface):\n",
    "    \"\"\" Helper function to create and save the profile report. \"\"\"\n",
    "    profile = ProfileReport(df, title=report_name, explorative=True)\n",
    "    if interface == \"html\":\n",
    "        profile.to_file(f\"{report_name}.html\")\n",
    "        logging.info(f\"Report {report_name} generated in html format, check files.\")\n",
    "    elif interface == \"widget\":\n",
    "        logging.info(f\"Report {report_name} will be generated as a widget, it might take a while.\")\n",
    "        profile.to_widgets()\n",
    "\n",
    "# Example usage\n",
    "# data_profiling(df)\n",
    "# data_profiling(df, num_columns=5)\n",
    "# data_profiling(df, specific_columns=['column1', 'column2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131218f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.451477Z",
     "iopub.status.busy": "2024-01-03T13:00:45.451133Z",
     "iopub.status.idle": "2024-01-03T13:00:45.468182Z",
     "shell.execute_reply": "2024-01-03T13:00:45.467247Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.451451Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_profiling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdeac0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f61cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e27de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.469498Z",
     "iopub.status.busy": "2024-01-03T13:00:45.469261Z",
     "iopub.status.idle": "2024-01-03T13:00:45.484722Z",
     "shell.execute_reply": "2024-01-03T13:00:45.483036Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.469476Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorize_column_types(df, unique_threshold=10):\n",
    "    \"\"\"\n",
    "    Counts and categorizes the columns in a Pandas DataFrame into numerical, categorical,\n",
    "    and potentially categorical (numeric but with low unique value count) types.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "    unique_threshold (int): The maximum number of unique values for a numeric column\n",
    "                            to be considered potentially categorical.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with counts of numerical, categorical, and potentially categorical columns.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "    categorical = df.select_dtypes(include=['object', 'category']).shape[1]\n",
    "    numerical = df.select_dtypes(include=['int64', 'float64']).shape[1]\n",
    "\n",
    "    # Check for numeric columns with low unique value counts\n",
    "    potentially_categorical = 0\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']):\n",
    "        if df[col].nunique() <= unique_threshold:\n",
    "            potentially_categorical += 1\n",
    "\n",
    "    return {\n",
    "        \"categorical\": categorical,\n",
    "        \"numerical\": numerical,\n",
    "        \"potentially_categorical\": potentially_categorical\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# categorize_column_types(df)\n",
    "\n",
    "def list_columns_by_type(df, column_type, unique_threshold=10):\n",
    "    \"\"\"\n",
    "    Lists the column names in a DataFrame based on their categorization as\n",
    "    'categorical', 'numerical', or 'potentially_categorical'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "    column_type (str): Type of columns to list ('categorical', 'numerical', 'potentially_categorical').\n",
    "    unique_threshold (int): The maximum number of unique values for a numeric column\n",
    "                            to be considered potentially categorical.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of column names that fall into the specified category.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "    if column_type not in ['categorical', 'numerical', 'potentially_categorical']:\n",
    "        raise ValueError(\"column_type must be 'categorical', 'numerical', or 'potentially_categorical'\")\n",
    "\n",
    "    if column_type == 'categorical':\n",
    "        return df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if column_type == 'numerical':\n",
    "        return df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    if column_type == 'potentially_categorical':\n",
    "        return [col for col in df.select_dtypes(include=['int64', 'float64']).columns\n",
    "                if df[col].nunique() <= unique_threshold]\n",
    "\n",
    "# Example usage\n",
    "# list_columns_by_type(df, 'potentially_categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028deab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.486273Z",
     "iopub.status.busy": "2024-01-03T13:00:45.485945Z",
     "iopub.status.idle": "2024-01-03T13:00:45.533572Z",
     "shell.execute_reply": "2024-01-03T13:00:45.531711Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.486251Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorize_column_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bb825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.536046Z",
     "iopub.status.busy": "2024-01-03T13:00:45.535558Z",
     "iopub.status.idle": "2024-01-03T13:00:45.565048Z",
     "shell.execute_reply": "2024-01-03T13:00:45.564093Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.536009Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_columns_by_type(df, 'potentially_categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbada95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "So the column 'URBAN_RURA' is actually categroical so we will change it, the rest of the potentially categorical is just potentially because function classified them as potentially categorical because they are almost empty we will get rid of them later ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6f0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h2 align=\"center\">\n",
    "    &#x1F4A1; <strong>Conclusion_2</strong> - Change data type of column 'URBAN_RURA' - do it in preprocessing also :)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b5eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:02.159961Z",
     "iopub.status.busy": "2024-01-03T13:33:02.159614Z",
     "iopub.status.idle": "2024-01-03T13:33:02.169411Z",
     "shell.execute_reply": "2024-01-03T13:33:02.167081Z",
     "shell.execute_reply.started": "2024-01-03T13:33:02.159934Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'URBAN_RURA' to a categorical column\n",
    "df.loc[:, 'URBAN_RURA'] = df['URBAN_RURA'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5092751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:02.315600Z",
     "iopub.status.busy": "2024-01-03T13:33:02.315105Z",
     "iopub.status.idle": "2024-01-03T13:33:02.354050Z",
     "shell.execute_reply": "2024-01-03T13:33:02.352124Z",
     "shell.execute_reply.started": "2024-01-03T13:33:02.315560Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorize_column_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd60e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:02.398426Z",
     "iopub.status.busy": "2024-01-03T13:33:02.397444Z",
     "iopub.status.idle": "2024-01-03T13:33:02.407752Z",
     "shell.execute_reply": "2024-01-03T13:33:02.406112Z",
     "shell.execute_reply.started": "2024-01-03T13:33:02.398387Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_columns_by_type(df, 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d98aa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Nice it works :) ok so our data types are correct let's analyze our missing values because there will be some, maybe not some but a looot ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436c64d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795fc34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.628852Z",
     "iopub.status.busy": "2024-01-03T13:00:45.628409Z",
     "iopub.status.idle": "2024-01-03T13:00:45.642636Z",
     "shell.execute_reply": "2024-01-03T13:00:45.640750Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.628814Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_missing_values(df, display_all_rows=False):\n",
    "    \"\"\"\n",
    "    Summarize missing values in the DataFrame, showing columns with missing values in descending order,\n",
    "    and providing a summary of how many columns have and don't have missing values.\n",
    "    Optionally displays all rows of the summary DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "        display_all_rows (bool): If True, display all rows of the summary. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns and their missing values count and percentage.\n",
    "    \"\"\"\n",
    "    # Option to display all rows\n",
    "    if display_all_rows:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # Count missing values for each column\n",
    "    missing_values = df.isnull().sum()\n",
    "\n",
    "    # Calculate the percentage of missing values\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "    # Filter out columns with no missing values and sort in descending order\n",
    "    missing_summary = pd.DataFrame({'Missing Values': missing_values[missing_values > 0],\n",
    "                                    'Percentage': missing_percentage[missing_values > 0]})\n",
    "    missing_summary = missing_summary.sort_values(by='Missing Values', ascending=False)\n",
    "\n",
    "    # Display the summary DataFrame\n",
    "    print(missing_summary)\n",
    "\n",
    "    # Reset display option to default\n",
    "    if display_all_rows:\n",
    "        pd.reset_option('display.max_rows')\n",
    "\n",
    "# Example usage\n",
    "# summarize_missing_values(df)\n",
    "# summarize_missing_values(df, display_all_rows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e02c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.646230Z",
     "iopub.status.busy": "2024-01-03T13:00:45.645746Z",
     "iopub.status.idle": "2024-01-03T13:00:45.662087Z",
     "shell.execute_reply": "2024-01-03T13:00:45.660338Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.646195Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_missing_values(df, display_all_rows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18def081",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h2 align=\"center\">\n",
    "    &#x1F4A1; <strong>Conclusion_3</strong> - Ok so we will drop columns that have more than 64% missing data for the second experiment (first version in 2v0.2_EDA_kaggle_python) - define this in the parameters in preprocessing.yaml file - <span style=\"color:green;\">Done &#x2705;</span>\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010a44d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "so we stayed with just 2797 in previous experiment, rows I will also perfrom the experiment with using features with 64% of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2389395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:18.908288Z",
     "iopub.status.busy": "2024-01-03T13:33:18.907930Z",
     "iopub.status.idle": "2024-01-03T13:33:18.914510Z",
     "shell.execute_reply": "2024-01-03T13:33:18.912971Z",
     "shell.execute_reply.started": "2024-01-03T13:33:18.908260Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features with lower than 64% of missing data \n",
    "features = [\n",
    "    'year',\n",
    "    'URBAN_RURA',\n",
    "    'country',\n",
    "    'alt',\n",
    "    'chrps',\n",
    "    'deathcount',\n",
    "    'latnum',\n",
    "    'longnum',\n",
    "    'lst',\n",
    "    'marketm0',\n",
    "    'marketm1',\n",
    "    'marketm2',\n",
    "    'marketm3',\n",
    "    'marketm4',\n",
    "    'marketm5',\n",
    "    'marketm6',  \n",
    "    'marketm7',\n",
    "    'marketm8',\n",
    "    'marketm9',\n",
    "    'markets0',\n",
    "    'markets1',\n",
    "    'markets2',\n",
    "    'markets3',\n",
    "    'markets4',\n",
    "    'markets5',\n",
    "    'markets6',  \n",
    "    'markets7',\n",
    "    'markets8',\n",
    "    'markets9',\n",
    "    'numevents',\n",
    "    'pasture',\n",
    "    'sif',\n",
    "    'slope',\n",
    "    'tree',\n",
    "    'tt00_500k'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee067309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:20.610260Z",
     "iopub.status.busy": "2024-01-03T13:33:20.609705Z",
     "iopub.status.idle": "2024-01-03T13:33:20.619291Z",
     "shell.execute_reply": "2024-01-03T13:33:20.617830Z",
     "shell.execute_reply.started": "2024-01-03T13:33:20.610219Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the columns specified in 'features' from the DataFrame\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b84b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:21.134406Z",
     "iopub.status.busy": "2024-01-03T13:33:21.134057Z",
     "iopub.status.idle": "2024-01-03T13:33:21.170967Z",
     "shell.execute_reply": "2024-01-03T13:33:21.169309Z",
     "shell.execute_reply.started": "2024-01-03T13:33:21.134378Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642082d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:27.039953Z",
     "iopub.status.busy": "2024-01-03T13:33:27.039547Z",
     "iopub.status.idle": "2024-01-03T13:33:27.056536Z",
     "shell.execute_reply": "2024-01-03T13:33:27.055259Z",
     "shell.execute_reply.started": "2024-01-03T13:33:27.039924Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_missing_values(df, display_all_rows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77580b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:45.740957Z",
     "iopub.status.busy": "2024-01-03T13:00:45.740535Z",
     "iopub.status.idle": "2024-01-03T13:00:45.748126Z",
     "shell.execute_reply": "2024-01-03T13:00:45.746512Z",
     "shell.execute_reply.started": "2024-01-03T13:00:45.740933Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def explore_missing_values(df):\n",
    "    \"\"\"\n",
    "    Visualizes the pattern of missing values in a pandas DataFrame using a heatmap.\n",
    "\n",
    "    The function creates a heatmap where missing values are marked, helping to identify\n",
    "    the pattern of missingness across different columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to analyze for missing values.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function outputs a visualization and does not return any value.\n",
    "\n",
    "    Usage:\n",
    "    - explore_missing_values(df)\n",
    "\n",
    "    Note: The function requires pandas, matplotlib, and seaborn libraries. Ensure\n",
    "    these are installed and imported before using the function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Missing data heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Using a custom color map: red for missing, green for not missing\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap=sns.color_palette([\"green\", \"red\"]))\n",
    "    plt.title(\"Heatmap of Missing Values\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# explore_missing_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5e25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:33:27.425115Z",
     "iopub.status.busy": "2024-01-03T13:33:27.423769Z",
     "iopub.status.idle": "2024-01-03T13:33:28.389175Z",
     "shell.execute_reply": "2024-01-03T13:33:28.387936Z",
     "shell.execute_reply.started": "2024-01-03T13:33:27.425037Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explore_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27641d8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "diffrent approach we will firstly deete rows which have 20 missing values in a row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c2e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:32:17.697489Z",
     "iopub.status.busy": "2024-01-03T13:32:17.697158Z",
     "iopub.status.idle": "2024-01-03T13:32:17.706676Z",
     "shell.execute_reply": "2024-01-03T13:32:17.705228Z",
     "shell.execute_reply.started": "2024-01-03T13:32:17.697467Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_rows_with_missing_values(dataframe: pd.DataFrame, threshold: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from a DataFrame based on a specified threshold of missing values.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame from which rows are to be removed.\n",
    "    - threshold (int): The maximum number of non-missing values in a row required \n",
    "                       for it not to be dropped. For example, if threshold is 3, \n",
    "                       rows with less than 3 non-missing values will be dropped.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A new DataFrame with rows dropped based on the specified threshold.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the threshold is negative or not an integer.\n",
    "    - TypeError: If the provided dataframe is not a pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(threshold, int) or threshold < 0:\n",
    "        raise ValueError(\"Threshold must be a non-negative integer\")\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        raise TypeError(\"The first argument must be a pandas DataFrame\")\n",
    "\n",
    "    return dataframe.dropna(thresh=(dataframe.shape[1] - threshold + 1), axis=0)\n",
    "\n",
    "# Example usage:\n",
    "# df = drop_rows_with_missing_values(df, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750852a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:36:56.110203Z",
     "iopub.status.busy": "2024-01-03T13:36:56.109701Z",
     "iopub.status.idle": "2024-01-03T13:36:56.122232Z",
     "shell.execute_reply": "2024-01-03T13:36:56.121364Z",
     "shell.execute_reply.started": "2024-01-03T13:36:56.110169Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = drop_rows_with_missing_values(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e260d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:36:56.197283Z",
     "iopub.status.busy": "2024-01-03T13:36:56.196699Z",
     "iopub.status.idle": "2024-01-03T13:36:56.228957Z",
     "shell.execute_reply": "2024-01-03T13:36:56.227314Z",
     "shell.execute_reply.started": "2024-01-03T13:36:56.197251Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114d066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:36:56.387874Z",
     "iopub.status.busy": "2024-01-03T13:36:56.387524Z",
     "iopub.status.idle": "2024-01-03T13:36:57.350656Z",
     "shell.execute_reply": "2024-01-03T13:36:57.349212Z",
     "shell.execute_reply.started": "2024-01-03T13:36:56.387849Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explore_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea335b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T14:17:44.205605Z",
     "iopub.status.busy": "2024-01-03T14:17:44.205237Z",
     "iopub.status.idle": "2024-01-03T14:17:44.218111Z",
     "shell.execute_reply": "2024-01-03T14:17:44.217113Z",
     "shell.execute_reply.started": "2024-01-03T14:17:44.205577Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_missing_values(df, display_all_rows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1367ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:46.538823Z",
     "iopub.status.busy": "2024-01-03T13:00:46.538492Z",
     "iopub.status.idle": "2024-01-03T13:00:46.549521Z",
     "shell.execute_reply": "2024-01-03T13:00:46.548749Z",
     "shell.execute_reply.started": "2024-01-03T13:00:46.538795Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_missing_values_by_group(df, group_columns, value_column):\n",
    "    \"\"\"\n",
    "    Visualizes missing values in the DataFrame grouped by specified columns using a heatmap,\n",
    "    showing both counts and percentages of missing values. If no missing values are found,\n",
    "    prints a message indicating this.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to analyze.\n",
    "    - group_columns (list of str): The column names to group the data by.\n",
    "    - value_column (str): The name of the column with missing values to analyze.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays seaborn heatmap visualizations of missing values by the specified groups or a message if no missing values are present.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a DataFrame that counts missing values for each group\n",
    "    missing_counts = df.groupby(group_columns)[value_column].apply(lambda x: x.isnull().sum()).reset_index(name='missing_count')\n",
    "    total_counts = df.groupby(group_columns)[value_column].apply(lambda x: len(x)).reset_index(name='total_count')\n",
    "\n",
    "    # Merge the missing counts with total counts to calculate percentages\n",
    "    missing_data = pd.merge(missing_counts, total_counts, on=group_columns)\n",
    "    missing_data['missing_percentage'] = (missing_data['missing_count'] / missing_data['total_count']) * 100\n",
    "\n",
    "    if missing_data['missing_count'].sum() == 0:\n",
    "        # If there are no missing values, print the information and return\n",
    "        print(f\"No missing values found in column '{value_column}'.\")\n",
    "        return\n",
    "\n",
    "    # Pivot the DataFrame to prepare for heatmap visualization\n",
    "    missing_counts_pivot = missing_data.pivot(index=group_columns[0], columns=group_columns[1], values='missing_count')\n",
    "    missing_percentage_pivot = missing_data.pivot(index=group_columns[0], columns=group_columns[1], values='missing_percentage')\n",
    "\n",
    "    # Plot the heatmap for missing counts\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(missing_counts_pivot, annot=True, fmt=\".0f\", cmap='RdYlGn_r', center=0)\n",
    "    plt.title(f'Missing Values Count in {value_column} by {\" and \".join(group_columns)}')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the heatmap for missing percentages\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(missing_percentage_pivot, annot=True, fmt=\".1f\", cmap='RdYlGn_r', center=0)\n",
    "    plt.title(f'Missing Values Percentage in {value_column} by {\" and \".join(group_columns)}')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# visualize_missing_values_by_group(df, ['country', 'year'], 'marketm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b176b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T14:12:55.324151Z",
     "iopub.status.busy": "2024-01-03T14:12:55.323636Z",
     "iopub.status.idle": "2024-01-03T14:12:55.937932Z",
     "shell.execute_reply": "2024-01-03T14:12:55.936407Z",
     "shell.execute_reply.started": "2024-01-03T14:12:55.324110Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_missing_values_by_group(df, ['country', 'year'], 'marketm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5fd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T14:18:42.076338Z",
     "iopub.status.busy": "2024-01-03T14:18:42.075766Z",
     "iopub.status.idle": "2024-01-03T14:18:42.667909Z",
     "shell.execute_reply": "2024-01-03T14:18:42.666054Z",
     "shell.execute_reply.started": "2024-01-03T14:18:42.076296Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_missing_values_by_group(df, ['country', 'year'], 'marketm6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a011e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:47.354436Z",
     "iopub.status.busy": "2024-01-03T13:00:47.354045Z",
     "iopub.status.idle": "2024-01-03T13:00:47.363547Z",
     "shell.execute_reply": "2024-01-03T13:00:47.362125Z",
     "shell.execute_reply.started": "2024-01-03T13:00:47.354403Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_rows_with_values(df, *args):\n",
    "    \"\"\"\n",
    "    Drops rows based on specified conditions. Conditions can be a single value for a column,\n",
    "    or multiple values for a column using a tuple with the column name followed by the values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "    - args: A sequence of arguments where each argument can be:\n",
    "            - A tuple of (column_name, value), to drop rows where column_name is value, or\n",
    "            - A tuple of (column_name, value1, value2, ...), to drop rows where column_name is any of value1, value2, ...\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the specified rows dropped.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process each argument provided to the function\n",
    "    for arg in args:\n",
    "        if not isinstance(arg, tuple):\n",
    "            raise TypeError(\"Each argument must be a tuple containing the column name and value(s) to drop.\")\n",
    "\n",
    "        column_name = arg[0]\n",
    "        values_to_drop = arg[1:]\n",
    "\n",
    "        # Ensure the column exists in the DataFrame\n",
    "        if column_name not in df.columns:\n",
    "            raise ValueError(f\"The column '{column_name}' is not in the DataFrame\")\n",
    "\n",
    "        # If only one value is provided, use equality\n",
    "        if len(values_to_drop) == 1:\n",
    "            df = df[df[column_name] != values_to_drop[0]]\n",
    "        else:\n",
    "            # If multiple values are provided, use isin to check for membership\n",
    "            df = df[~df[column_name].isin(values_to_drop)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# To drop all rows with country '8'\n",
    "# df = drop_rows_with_values(df, ('country', '8'))\n",
    "\n",
    "# To drop rows with Bangladesh in 'country' and years 2004, 2007, 2001 in 'year'\n",
    "# df = drop_rows_with_values(df, ('country', 'Bangladesh'), ('year', 2004, 2007, 2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357b5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T13:00:49.589158Z",
     "iopub.status.busy": "2024-01-03T13:00:49.588862Z",
     "iopub.status.idle": "2024-01-03T13:00:49.598181Z",
     "shell.execute_reply": "2024-01-03T13:00:49.596825Z",
     "shell.execute_reply.started": "2024-01-03T13:00:49.589134Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(df: pd.DataFrame, columns: Union[str, List[str]] = None, verbose: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes all rows containing missing values either from the whole DataFrame or from specific columns.\n",
    "    This function adds validation for input types and optional logging for more informative output.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame from which to remove rows.\n",
    "    - columns (Union[str, List[str]], optional): Column or list of columns to consider for row removal.\n",
    "                                                 If None, consider all columns. Default is None.\n",
    "    - verbose (bool, optional): If True, prints the number of rows removed. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with rows containing missing values removed.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If `df` is not a DataFrame or `columns` are not found in `df`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input 'df' must be a pandas DataFrame.\")\n",
    "    \n",
    "    if columns is not None:\n",
    "        if isinstance(columns, list):\n",
    "            missing_cols = [col for col in columns if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Columns not found in DataFrame: {missing_cols}\")\n",
    "        elif isinstance(columns, str):\n",
    "            if columns not in df.columns:\n",
    "                raise ValueError(f\"Column '{columns}' not found in DataFrame.\")\n",
    "        else:\n",
    "            raise ValueError(\"'columns' must be a string or a list of strings.\")\n",
    "\n",
    "    # DataFrame shape before removal\n",
    "    initial_shape = df.shape\n",
    "\n",
    "    # Removing rows with missing values\n",
    "    if columns is not None:\n",
    "        df_cleaned = df.dropna(subset=columns)\n",
    "    else:\n",
    "        df_cleaned = df.dropna()\n",
    "\n",
    "    # Logging\n",
    "    if verbose:\n",
    "        removed_rows = initial_shape[0] - df_cleaned.shape[0]\n",
    "        print(f\"Removed {removed_rows} rows with missing values.\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Example 1: Remove missing values from entire DataFrame\n",
    "# df = remove_rows_with_missing_values(sample_df, verbose=True)\n",
    "\n",
    "# Example 2: Remove missing values from specific column 'A'\n",
    "# df = remove_rows_with_missing_values(sample_df, columns='A', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7337fb7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example 2: Remove missing values from specific column 'A'\n",
    "# df = remove_rows_with_missing_values(sample_df, columns='A', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78d21f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Experiment with features which has 64% of missing data let's see with how many records we will stay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e4ed8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bd95e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843157c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4251279,
     "sourceId": 7325201,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.882665,
   "end_time": "2024-01-03T14:51:18.606333",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-03T14:51:14.723668",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
